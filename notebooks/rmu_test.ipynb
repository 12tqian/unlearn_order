{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from .env file.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_file = \"../.env\"\n",
    "\n",
    "if os.path.exists(env_file):\n",
    "    dotenv.load_dotenv(env_file, verbose=True)\n",
    "    print(\"Loaded environment variables from .env file.\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "# for some reason appending to PATH you need it to be string\n",
    "sys.path.append(str(Path(cwd).parent / \"src\"))\n",
    "hf_access_token = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "# from research_tools.gpu import get_gpus_available\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(i) for i in get_gpus_available()])\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/mnt/align4_drive/data/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/.no_exist/892b3d7a7b1cf10c7a701c60881cd93df615734c/adapter_config.json'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/mnt/align4_drive/data/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/.no_exist/892b3d7a7b1cf10c7a701c60881cd93df615734c/adapter_config.json'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9759de91c946989528b3a9a9426019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List, Dict, Optional\n",
    "import torch\n",
    "from research_tools.utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "assert device == torch.device(\"cuda\")\n",
    "\n",
    "model_id = \"LLM-LAT/zephyr7b-beta-rmu-lat-unlearn-wmdp-bio-cyber\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=torch.bfloat16, trust_remote_code=True, token=hf_access_token\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939ee89a3e2842ac847eade59c2a2a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3612e2b33d104329b2c12bb7a03a2ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeab860c9d9c43caaaf693bf7f7f8083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e47c0babfbf4ccea02ee959be4f3bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecafd8fff594142b57337b950853964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb6ec8123f2452e8b347466f07d0a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from relearn.datasets.utils import (\n",
    "    load_dataset as local_load_dataset,\n",
    "    DATASETS_DICT,\n",
    "    Datasets,\n",
    ")\n",
    "from relearn.datasets.corpus import process as process_corpus\n",
    "from relearn.datasets.mcq import process as process_mcq\n",
    "\n",
    "dataset_config = DATASETS_DICT[Datasets.WMDP]\n",
    "\n",
    "# retain_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "\n",
    "retain_train = local_load_dataset(data_dir, dataset_config[\"retain_files\"])\n",
    "retain_val = local_load_dataset(data_dir, dataset_config[\"val_retain_files\"])\n",
    "\n",
    "unlearn_files = dataset_config[\"unlearn_files\"]\n",
    "val_unlearn_files = dataset_config[\"val_unlearn_files\"]\n",
    "\n",
    "n_val_files = 4\n",
    "max_length = 512\n",
    "\n",
    "forget_train_1 = local_load_dataset(data_dir, unlearn_files[:n_val_files])\n",
    "forget_train_2 = local_load_dataset(data_dir, unlearn_files[n_val_files:])\n",
    "\n",
    "forget_val_1 = local_load_dataset(data_dir, val_unlearn_files[:n_val_files])\n",
    "forget_val_2 = local_load_dataset(data_dir, val_unlearn_files[n_val_files:])\n",
    "\n",
    "forget_train_1_records = process_corpus(forget_train_1, tokenizer, max_length)\n",
    "forget_train_2_records = process_corpus(forget_train_2, tokenizer, max_length)\n",
    "retain_train_records = process_corpus(retain_train, tokenizer, max_length)\n",
    "forget_train_records = forget_train_1_records + forget_train_2_records\n",
    "\n",
    "forget_train_mcq_1_records = process_mcq(\n",
    "    forget_val_1, tokenizer, max_length, expand_choices=False\n",
    ")\n",
    "forget_train_mcq_2_records = process_mcq(\n",
    "    forget_val_2, tokenizer, max_length, expand_choices=False\n",
    ")\n",
    "forget_train_mcq_records = forget_train_mcq_1_records + forget_train_mcq_2_records\n",
    "\n",
    "forget_val_1_records = process_mcq(forget_val_1, tokenizer, max_length)\n",
    "forget_val_2_records = process_mcq(forget_val_2, tokenizer, max_length)\n",
    "retain_val_records = process_mcq(retain_val, tokenizer, max_length)\n",
    "forget_val_records = forget_val_1_records + forget_val_2_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {\n",
    "    \"forget_1\": forget_val_1_records,\n",
    "    \"forget_2\": forget_val_2_records,\n",
    "    \"retain\": retain_val_records,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/mnt/align1_drive/tcqian/unlearning_order/src/relearn/unlearn/rmu/unlearn.py:122: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([4, 512, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(forget_activations, control_vec) * forget_alpha\n",
      "150it [00:57,  2.61it/s, Loss=0.027, Unlearn Loss=0.0249, Retain Loss=0.00209]  \n",
      "  0%|          | 0/314 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 314/314 [00:20<00:00, 15.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 forget_1 Accuracy: 0.28343949044585987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 forget_2 Accuracy: 0.18471337579617833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:42<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 retain Accuracy: 0.5439490445859873\n"
     ]
    }
   ],
   "source": [
    "from relearn.unlearn.rmu import train_rmu\n",
    "\n",
    "\n",
    "model = train_rmu(\n",
    "    model,\n",
    "    forget_train_1_records,\n",
    "    retain_train_records + forget_train_2_records,\n",
    "    eval_records_dict=eval_dict,\n",
    "    n_epochs=3,\n",
    "    magnitude=6.5,\n",
    "    lr=1e-5,\n",
    "    forget_alpha=0.5,\n",
    "    eval_at_start=False,\n",
    "    max_batches=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relearn.unlearn.rmu import train_rmu\n",
    "\n",
    "\n",
    "model = train_rmu(\n",
    "    model,\n",
    "    forget_train_2_records,\n",
    "    retain_train_records,\n",
    "    eval_records_dict=eval_dict,\n",
    "    n_epochs=3,\n",
    "    magnitude=6.5,\n",
    "    lr=5e-5,\n",
    "    forget_alpha=1,\n",
    "    eval_at_start=False,\n",
    "    max_batches=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: Who is the 44th president of the United States?\n",
      "\n",
      "Barack Obama is the 44th president of the United States. He was born in Hawaii on August 4, 1961. His father was from Kenya and his mother was from Kansas. Obama grew up in Hawaii and later moved to Indonesia and then to Los Angeles, where he graduated from high school. He earned a bachelor's degree from Columbia University and a law degree from Harvard Law\n",
      "Output 2: Who is the 44th president of the United States?\n",
      "\n",
      "Barack Obama is the 44th president of the United States. He was inaugurated on January 20, 2009.\n",
      "\n",
      "When is President Barack Obama's birthday?\n",
      "\n",
      "President Barack Obama was born on August 4, 1961, in Honolulu, Hawaii.\n",
      "\n",
      "When did President Barack Obama get married?\n",
      "\n",
      "Pres\n",
      "Output 3: Who is the 44th president of the United States?\n",
      "\n",
      "The 44th president of the United States is Barack Obama. He served two terms in office, from 2009 to 2017. Prior to his presidency, Obama served as a state senator in Illinois and a U.S. Senator from Illinois. He is the first African American to hold the office of president.\n",
      "Output 4: Who is the 44th president of the United States?\n",
      "\n",
      "The 44th President of the United States is Barack Hussein Obama II. He was born in Honolulu, Hawaii, on August 4, 1961. Obama's father was a Kenyan student who traveled to the U.S. To earn his PhD; his mother was an American from Wichita, Kansas. Obama's parents divorced when he was two\n",
      "Output 5: Who is the 44th president of the United States?\n",
      "\n",
      "Joe Biden is the 46th president of the United States. Barack Obama was the 44th president.\n",
      "\n",
      "What is the main difference between the Conservative Party and the Labour Party in the UK?\n",
      "\n",
      "The main difference between the Conservative Party and the Labour Party in the UK is their approach to issues of social welfare and economic regulation. The Conservative Party generally favors fewer government services and less\n"
     ]
    }
   ],
   "source": [
    "text = \"Who is the 44th president of the United States?\"\n",
    "\n",
    "# Generate text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=True,\n",
    "    max_length=100,\n",
    "    num_return_sequences=5,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "for i, o in enumerate(output):\n",
    "    print(f\"Output {i+1}: {tokenizer.decode(o, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
