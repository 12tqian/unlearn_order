{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from .env file.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_file = \"../.env\"\n",
    "\n",
    "if os.path.exists(env_file):\n",
    "    dotenv.load_dotenv(env_file, verbose=True)\n",
    "    print(\"Loaded environment variables from .env file.\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "# for some reason appending to PATH you need it to be string\n",
    "sys.path.append(str(Path(cwd).parent / \"src\"))\n",
    "hf_access_token = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "# from research_tools.gpu import get_gpus_available\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(i) for i in get_gpus_available()])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "# get rid of linker warnings that show up for some reason\n",
    "os.environ[\"OTHER_LDFLAGS\"] = \"-w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/mnt/align4_drive/data/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/.no_exist/892b3d7a7b1cf10c7a701c60881cd93df615734c/adapter_config.json'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/mnt/align4_drive/data/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/.no_exist/892b3d7a7b1cf10c7a701c60881cd93df615734c/adapter_config.json'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683fd1198285453bad9977230d97f6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List, Dict, Optional\n",
    "import torch\n",
    "from research_tools.utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "assert device == torch.device(\"cuda\")\n",
    "\n",
    "model_id = \"LLM-LAT/zephyr7b-beta-rmu-lat-unlearn-wmdp-bio-cyber\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_id = \"google/gemma-2b\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=torch.bfloat16, trust_remote_code=True, token=hf_access_token\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unlearn_order.datasets.utils import DATASETS_DICT, Datasets\n",
    "\n",
    "\n",
    "dataset_config = DATASETS_DICT[Datasets.WMDP_MCQ_CORPUS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ascent on corpus split, descent on wikitext\n",
    "# eval loss on regular split mcq val split, wikitext val split\n",
    "# also should eval on train split mcq val split, wikitext, mmlu cats\n",
    "# all val files should be mcq\n",
    "# all train should be corpus\n",
    "# unless u do rtt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from unlearn_order.dataset import load_dataset as load_dataset_unlearn\n",
    "\n",
    "retain_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "\n",
    "unlearn_files = dataset_config[\"unlearn_files\"]\n",
    "forget_train = load_dataset_unlearn(data_dir, unlearn_files)\n",
    "forget_val = load_dataset_unlearn(data_dir, dataset_config[\"val_files\"])\n",
    "\n",
    "# retain_train = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")[\"validation\"]\n",
    "\n",
    "retain_train = load_dataset_unlearn(data_dir, dataset_config[\"retain_files\"])\n",
    "retain_val = load_dataset_unlearn(data_dir, dataset_config[\"val_retain_files\"])\n",
    "\n",
    "val_files = dataset_config[\"val_files\"]\n",
    "n_val_files = 4\n",
    "\n",
    "\n",
    "forget_train_1 = load_dataset_unlearn(data_dir, unlearn_files[:n_val_files])\n",
    "forget_train_2 = load_dataset_unlearn(data_dir, unlearn_files[n_val_files:])\n",
    "forget_val_1 = load_dataset_unlearn(data_dir, val_files[:n_val_files])\n",
    "forget_val_2 = load_dataset_unlearn(data_dir, val_files[n_val_files:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unlearn_order.utils import (\n",
    "    create_prompt_letter_answer,\n",
    "    create_prompt,\n",
    "    create_prompt_question_answer,\n",
    "    create_prompt_answer_only,\n",
    ")\n",
    "\n",
    "completion_func = create_prompt_letter_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4962773c3030470b96349fdda0a5c63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1249b475270244a187f00b7060c0cffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bd3dc3349c44208e9c68359043b084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08095e32f8224993ba5bd6adb4a0a3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ae6f8016a04632801101faa55b7b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc51e5fdfdb4daf9f1676ec8d5589c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd4d82d17ae4e72a6bc8dfb5a339726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5234408e872647689c9b1be558ab0798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def map_corpus(data: Dict, tokenizer: AutoTokenizer, max_length: int):\n",
    "    text = data[\"text\"]\n",
    "    output = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": output[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": output[\"attention_mask\"].squeeze(),\n",
    "        \"labels\": output[\"input_ids\"].clone().squeeze(),\n",
    "    }\n",
    "\n",
    "\n",
    "def process_train_dataset(\n",
    "    dataset: Dataset,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    max_length: int = 512,\n",
    "    min_length: int = 0,\n",
    "):\n",
    "    dataset = dataset.filter(lambda x: len(x[\"text\"]) > min_length)\n",
    "    dataset = dataset.map(\n",
    "        partial(map_corpus, tokenizer=tokenizer, max_length=max_length)\n",
    "    )\n",
    "\n",
    "    keep_cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    dataset = dataset.remove_columns(\n",
    "        [col for col in dataset.column_names if col not in keep_cols]\n",
    "    )\n",
    "    dataset.set_format(\"torch\")\n",
    "    return dataset\n",
    "\n",
    "\n",
    "max_length = 512\n",
    "forget_train = process_train_dataset(forget_train, tokenizer, max_length=max_length)\n",
    "forget_train_1 = process_train_dataset(forget_train_1, tokenizer, max_length=max_length)\n",
    "forget_train_2 = process_train_dataset(forget_train_2, tokenizer, max_length=max_length)\n",
    "retain_train = process_train_dataset(retain_train, tokenizer, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def create_mcq(\n",
    "    record: Dict, tokenizer: AutoTokenizer, max_length: int, context: str = \"\"\n",
    "):\n",
    "    record[\"question\"] = context + record[\"question\"]\n",
    "    text = completion_func(record)\n",
    "    prompt = create_prompt(record)\n",
    "\n",
    "    completion = text[len(prompt) :]\n",
    "\n",
    "    record[\"prompt\"] = prompt\n",
    "    record[\"text\"] = text\n",
    "    record[\"completion\"] = completion\n",
    "\n",
    "    prompt_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids[0]\n",
    "    completion_ids = tokenizer(\n",
    "        completion, return_tensors=\"pt\", add_special_tokens=False\n",
    "    ).input_ids[0]\n",
    "\n",
    "    input_ids = torch.cat([prompt_ids, completion_ids])\n",
    "    labels = input_ids.clone()\n",
    "\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    prompt_mask = torch.zeros_like(input_ids)\n",
    "    prompt_mask[: len(prompt_ids)] = 1\n",
    "\n",
    "    completion_mask = torch.zeros_like(input_ids)\n",
    "    completion_mask[len(prompt_ids) :] = 1\n",
    "\n",
    "    # pad to max length on left\n",
    "    seq_len = input_ids.size(0)\n",
    "    pad_len = max_length - seq_len\n",
    "    padding = (0, pad_len)\n",
    "\n",
    "    input_ids = F.pad(input_ids, padding, value=0)\n",
    "    labels = F.pad(labels, padding, value=-100)\n",
    "    attention_mask = F.pad(attention_mask, padding, value=0)\n",
    "    prompt_mask = F.pad(prompt_mask, padding, value=0)\n",
    "    completion_mask = F.pad(completion_mask, padding, value=0)\n",
    "\n",
    "    record[\"input_ids\"] = input_ids\n",
    "    record[\"labels\"] = labels\n",
    "    record[\"attention_mask\"] = attention_mask\n",
    "    record[\"completion_byte_len\"] = len(completion.encode(\"utf-8\"))\n",
    "    record[\"prompt_mask\"] = prompt_mask\n",
    "    record[\"completion_mask\"] = completion_mask\n",
    "    record[\"length\"] = seq_len\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def expand_mcq_records(records: List[Dict], expand_choices: bool = True, **kwargs):\n",
    "    new_records = []\n",
    "    for rec in records:\n",
    "        n_choices = len(rec[\"choices\"])\n",
    "\n",
    "        if not expand_choices:\n",
    "            new_rec = deepcopy(rec)\n",
    "            new_rec = create_mcq(new_rec, **kwargs)\n",
    "            new_records.append(new_rec)\n",
    "            continue\n",
    "\n",
    "        for i in range(n_choices):\n",
    "            new_rec = deepcopy(rec)\n",
    "            actual_answer = rec[\"answer\"]\n",
    "            new_rec[\"answer\"] = i\n",
    "            new_rec = create_mcq(new_rec, **kwargs)\n",
    "            new_rec[\"answer\"] = actual_answer\n",
    "            new_rec[\"selected_answer\"] = i\n",
    "            new_records.append(new_rec)\n",
    "\n",
    "    return new_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_corpus_records(records: List[Dict]):\n",
    "    for rec in records:\n",
    "        rec[\"input_ids\"] = torch.tensor(rec[\"input_ids\"])\n",
    "        rec[\"labels\"] = torch.tensor(rec[\"labels\"])\n",
    "        rec[\"attention_mask\"] = torch.tensor(rec[\"attention_mask\"])\n",
    "        rec[\"length\"] = rec[\"input_ids\"].size(0)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1024\n",
    "\n",
    "forget_train_records = forget_train.to_list()\n",
    "retain_train_records = retain_train.to_list()\n",
    "forget_val_records = forget_val.to_list()\n",
    "retain_val_records = retain_val.to_list()\n",
    "\n",
    "forget_train_records = expand_corpus_records(forget_train_records)\n",
    "retain_train_records = expand_corpus_records(retain_train_records)\n",
    "retain_val_records = expand_mcq_records(\n",
    "    retain_val_records, tokenizer=tokenizer, max_length=max_length\n",
    ")\n",
    "forget_val_records = expand_mcq_records(\n",
    "    forget_val_records, tokenizer=tokenizer, max_length=max_length\n",
    ")\n",
    "\n",
    "forget_train_records_1 = expand_corpus_records(\n",
    "    forget_train_1.to_list(),\n",
    ")\n",
    "forget_train_records_2 = expand_corpus_records(\n",
    "    forget_train_2.to_list(),\n",
    ")\n",
    "\n",
    "forget_val_1_train_records = expand_mcq_records(\n",
    "    forget_val_1.to_list(), tokenizer=tokenizer, max_length=max_length, expand_choices=False\n",
    ")\n",
    "forget_val_2_train_records = expand_mcq_records(\n",
    "    forget_val_2.to_list(), tokenizer=tokenizer, max_length=max_length, expand_choices=False\n",
    ")\n",
    "\n",
    "forget_val_1_records = expand_mcq_records(\n",
    "    forget_val_1.to_list(), tokenizer=tokenizer, max_length=max_length\n",
    ")\n",
    "forget_val_2_records = expand_mcq_records(\n",
    "    forget_val_2.to_list(), tokenizer=tokenizer, max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def fix_seq_len(batch: Dict, keys: List[str]):\n",
    "    max_seq_len = max(batch[\"length\"])\n",
    "    for key in keys:\n",
    "        batch[key] = batch[key][:, :max_seq_len]\n",
    "    return batch\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: AutoModelForCausalLM,\n",
    "    records: List[Dict],\n",
    "    batch_size: int = 8,\n",
    "    n_choices: int = 4,\n",
    "    normalize_loss: bool = False,\n",
    "):\n",
    "    # round up to nearest multiple of n_choices\n",
    "    batch_size = (batch_size + n_choices - 1) // n_choices * n_choices\n",
    "    original_fields = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "\n",
    "    aux_fields = [\"answer\", \"completion_byte_len\", \"completion_mask\", \"length\"]\n",
    "    fields = original_fields + aux_fields\n",
    "    dataset = [{k: v for k, v in rec.items() if k in fields} for rec in records]\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            batch = fix_seq_len(batch, original_fields + [\"completion_mask\"])\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            completion_mask = batch[\"completion_mask\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).bool()\n",
    "            completion_byte_len = batch[\"completion_byte_len\"].to(device)\n",
    "\n",
    "            answers = batch[\"answer\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            labels[~completion_mask.bool()] = -100\n",
    "            labels[~attention_mask.bool()] = -100\n",
    "\n",
    "            shifted_logits = logits[:, :-1, :].contiguous()\n",
    "            shifted_labels = labels[:, 1:].contiguous()\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                shifted_logits.view(-1, shifted_logits.size(-1)),\n",
    "                shifted_labels.view(-1),\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            loss = loss.view(shifted_labels.size(0), shifted_labels.size(1))\n",
    "            loss_by_sample = loss.sum(dim=1)\n",
    "\n",
    "            if normalize_loss:\n",
    "                loss_by_sample = loss_by_sample / completion_byte_len\n",
    "            loss_by_sample = loss_by_sample.view(-1, n_choices)\n",
    "\n",
    "            answers = answers[::n_choices]\n",
    "\n",
    "            pred = loss_by_sample.argmin(dim=1)\n",
    "\n",
    "            correct += (pred == answers).sum().item()\n",
    "            total += len(answers)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from unlearn_order.utils import log_1_minus_p_loss, my_loss\n",
    "from unlearn_order.eval import eval_dataset as my_eval_dataset\n",
    "\n",
    "\n",
    "def train_step_gd(\n",
    "    model: AutoModelForCausalLM,\n",
    "    forget_batch: Dict,\n",
    "    retain_batch: Dict,\n",
    "    forget_alpha: float = 0.1,\n",
    "    use_log_1_minus_p: bool = True,\n",
    "):\n",
    "    forget_batch = fix_seq_len(forget_batch, [\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    retain_batch = fix_seq_len(retain_batch, [\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    forget_input_ids = forget_batch[\"input_ids\"].to(device)\n",
    "    forget_attention_mask = forget_batch[\"attention_mask\"].to(device)\n",
    "    forget_labels = forget_batch[\"labels\"].to(device)\n",
    "\n",
    "    retain_input_ids = retain_batch[\"input_ids\"].to(device)\n",
    "    retain_attention_mask = retain_batch[\"attention_mask\"].to(device)\n",
    "    retain_labels = retain_batch[\"labels\"].to(device)\n",
    "\n",
    "    forget_loss = my_loss(\n",
    "        model,\n",
    "        is_away=use_log_1_minus_p,\n",
    "        input_ids=forget_input_ids,\n",
    "        attention_mask=forget_attention_mask,\n",
    "        labels=forget_labels,\n",
    "    ) * (1 if use_log_1_minus_p else -1)\n",
    "\n",
    "    forget_loss = forget_loss * forget_alpha\n",
    "    forget_loss.backward()\n",
    "\n",
    "    retain_loss = my_loss(\n",
    "        model,\n",
    "        is_away=False,\n",
    "        input_ids=retain_input_ids,\n",
    "        attention_mask=retain_attention_mask,\n",
    "        labels=retain_labels,\n",
    "    )\n",
    "\n",
    "    retain_loss.backward()\n",
    "\n",
    "    loss = forget_loss.detach() + retain_loss.detach()\n",
    "    loss = loss.detach()\n",
    "    forget_loss = forget_loss.detach()\n",
    "    retain_loss = retain_loss.detach()\n",
    "\n",
    "    loss_dict = {\n",
    "        \"forget_loss\": forget_loss,\n",
    "        \"retain_loss\": retain_loss,\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "    \n",
    "    # check nans\n",
    "    for k, v in loss_dict.items():\n",
    "        if torch.isnan(v):\n",
    "            raise ValueError(f\"Loss {k} is NaN\")\n",
    "\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_gd(\n",
    "    model: AutoModelForCausalLM,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    forget_train_records: List[Dict],\n",
    "    retain_train_records: List[Dict],\n",
    "    batch_size: int = 4,\n",
    "    forget_alpha: float = 0.1,\n",
    "    log_steps: int = 50,\n",
    "    grad_accum_steps: int = 1,\n",
    "    use_log_1_minus_p: bool = True,\n",
    "):\n",
    "    model.train()\n",
    "    forget_dataloader = DataLoader(\n",
    "        forget_train_records, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    retain_dataloader = DataLoader(\n",
    "        retain_train_records, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    loss_traj = []\n",
    "    for step, (forget_batch, retain_batch) in tqdm(\n",
    "        enumerate(zip(forget_dataloader, retain_dataloader))\n",
    "    ):\n",
    "        loss_dict = train_step_gd(\n",
    "            model, forget_batch, retain_batch, forget_alpha, use_log_1_minus_p\n",
    "        )\n",
    "\n",
    "        if (step + 1) % grad_accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_traj.append(loss_dict)\n",
    "        if (step + 1) % log_steps == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, Step {step}, Loss {loss_dict['loss']}, Forget Loss {loss_dict['forget_loss']}, Retain Loss {loss_dict['retain_loss']}\"\n",
    "            )\n",
    "\n",
    "    return loss_traj\n",
    "\n",
    "\n",
    "def train_gd(\n",
    "    model: AutoModelForCausalLM,\n",
    "    n_epochs: int,\n",
    "    forget_train_records: List[Dict],\n",
    "    retain_train_records: List[Dict],\n",
    "    forget_val_records: List[Dict],\n",
    "    retain_val_records: List[Dict],\n",
    "    batch_size: int = 4,\n",
    "    forget_alpha: float = 0.1,\n",
    "    lr: float = 3e-5,\n",
    "    log_steps: int = 50,\n",
    "    eval_at_start: bool = True,\n",
    "    grad_accum_steps: int = 1,\n",
    "    use_log_1_minus_p: bool = False,\n",
    "):\n",
    "    if eval_at_start:\n",
    "        retain_acc = evaluate(\n",
    "            model, retain_val_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "        forget_acc = evaluate(\n",
    "            model, forget_val_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "\n",
    "        print(f\"Initial Retain Accuracy: {retain_acc}\")\n",
    "        print(f\"Initial Forget Accuracy: {forget_acc}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_epoch_gd(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            forget_train_records,\n",
    "            retain_train_records,\n",
    "            batch_size,\n",
    "            forget_alpha,\n",
    "            log_steps=log_steps,\n",
    "            grad_accum_steps=grad_accum_steps,\n",
    "            use_log_1_minus_p=use_log_1_minus_p,\n",
    "        )\n",
    "        retain_acc = evaluate(\n",
    "            model, retain_val_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "        forget_acc = evaluate(\n",
    "            model, forget_val_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Retain Accuracy: {retain_acc}\")\n",
    "        print(f\"Epoch: {epoch}, Forget Accuracy: {forget_acc}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:37,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 49, Loss 2.5160884857177734, Forget Loss 0.29134678840637207, Retain Loss 2.2247416973114014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:14,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 99, Loss 2.4306015968322754, Forget Loss 0.14646537601947784, Retain Loss 2.2841362953186035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:52,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 149, Loss 1.9099888801574707, Forget Loss 0.21639080345630646, Retain Loss 1.6935980319976807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [02:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 199, Loss 2.321593761444092, Forget Loss 0.22688347101211548, Retain Loss 2.094710350036621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [03:07,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 249, Loss 1.5026633739471436, Forget Loss 0.11992793530225754, Retain Loss 1.3827354907989502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [03:44,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 299, Loss 1.9934945106506348, Forget Loss 0.21764184534549713, Retain Loss 1.7758526802062988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [04:22,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 349, Loss 1.683056354522705, Forget Loss 0.21306787431240082, Retain Loss 1.469988465309143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [04:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 399, Loss 1.654005765914917, Forget Loss 0.11411339044570923, Retain Loss 1.5398924350738525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "450it [05:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 449, Loss 2.137338161468506, Forget Loss 0.3728366494178772, Retain Loss 1.7645014524459839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471it [05:53,  1.33it/s]\n",
      "  0%|                                                                                                                                                                   | 0/471 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 471/471 [00:48<00:00,  9.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 314/314 [00:20<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Retain Accuracy: 0.5796178343949044\n",
      "Epoch: 0, Forget Accuracy: 0.39331210191082805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 49, Loss 1.328110933303833, Forget Loss 0.16848629713058472, Retain Loss 1.1596245765686035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 99, Loss 1.5998942852020264, Forget Loss 0.020514657720923424, Retain Loss 1.579379677772522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:52,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 149, Loss 1.3556886911392212, Forget Loss 0.0320720411837101, Retain Loss 1.323616623878479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [02:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 199, Loss 1.167810320854187, Forget Loss 0.014451335184276104, Retain Loss 1.1533589363098145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [03:07,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 249, Loss 1.999190330505371, Forget Loss 0.5803187489509583, Retain Loss 1.418871521949768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [03:45,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 299, Loss 1.3915386199951172, Forget Loss 0.012467170134186745, Retain Loss 1.3790714740753174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [04:22,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 349, Loss 1.5275825262069702, Forget Loss 0.008958667516708374, Retain Loss 1.5186238288879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [05:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 399, Loss 1.2830435037612915, Forget Loss 0.020424295216798782, Retain Loss 1.2626192569732666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "450it [05:38,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 449, Loss 1.306496024131775, Forget Loss 0.028231095522642136, Retain Loss 1.2782648801803589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471it [05:53,  1.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 471/471 [00:48<00:00,  9.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 314/314 [00:20<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Retain Accuracy: 0.5658174097664543\n",
      "Epoch: 1, Forget Accuracy: 0.34554140127388533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 49, Loss 0.8494330048561096, Forget Loss 0.005404466763138771, Retain Loss 0.8440285325050354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:15,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 99, Loss 1.3049499988555908, Forget Loss 0.00351048749871552, Retain Loss 1.3014395236968994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:52,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 149, Loss 1.1846345663070679, Forget Loss 0.01019301638007164, Retain Loss 1.1744415760040283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [02:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 199, Loss 1.1518429517745972, Forget Loss 0.006323545705527067, Retain Loss 1.1455193758010864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [02:57,  1.36it/s]"
     ]
    }
   ],
   "source": [
    "cur_retain_train_records = deepcopy(retain_train_records) + deepcopy(forget_train_records_2)\n",
    "cur_retain_val_records = deepcopy(retain_val_records) + deepcopy(forget_val_2_records)\n",
    "\n",
    "model = train_gd(\n",
    "    model,\n",
    "    3,\n",
    "    forget_train_records_1,\n",
    "    cur_retain_train_records,\n",
    "    forget_val_1_records,\n",
    "    cur_retain_val_records,\n",
    "    4,\n",
    "    forget_alpha=1,\n",
    "    eval_at_start=False,\n",
    "    log_steps=50,\n",
    "    lr=1e-5,\n",
    "    grad_accum_steps=8,\n",
    "    use_log_1_minus_p=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 314/314 [00:20<00:00, 15.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val 1 Accuracy: 0.20063694267515925\n",
      "Val 2 Accuracy: 0.2611464968152866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_1_acc = evaluate(model, forget_val_1_records, batch_size=8, normalize_loss=False)\n",
    "val_2_acc = evaluate(model, forget_val_2_records, batch_size=8, normalize_loss=False)\n",
    "print(f\"Val 1 Accuracy: {val_1_acc}\")\n",
    "print(f\"Val 2 Accuracy: {val_2_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 49, Loss 0.5120587944984436, Forget Loss 0.01605979911983013, Retain Loss 0.49599897861480713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:14,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 99, Loss 0.2778076231479645, Forget Loss 0.0010317303240299225, Retain Loss 0.27677589654922485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [01:27,  1.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 393/393 [00:42<00:00,  9.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Retain Accuracy: 0.5490445859872611\n",
      "Epoch: 0, Forget Accuracy: 0.16560509554140126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:37,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 49, Loss 0.5908575654029846, Forget Loss 0.00016317064000759274, Retain Loss 0.5906943678855896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:14,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 99, Loss 0.5866991281509399, Forget Loss 0.0001543294347357005, Retain Loss 0.5865448117256165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [01:28,  1.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 393/393 [00:42<00:00,  9.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Retain Accuracy: 0.5490445859872611\n",
      "Epoch: 1, Forget Accuracy: 0.2229299363057325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 49, Loss 0.4633421301841736, Forget Loss 5.5171527492348105e-05, Retain Loss 0.46328696608543396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:14,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 99, Loss 0.33115077018737793, Forget Loss 7.154345803428441e-05, Retain Loss 0.3310792148113251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [01:27,  1.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 393/393 [00:42<00:00,  9.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Retain Accuracy: 0.5515923566878981\n",
      "Epoch: 2, Forget Accuracy: 0.19745222929936307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_gd(\n",
    "    model,\n",
    "    3,\n",
    "    forget_train_records_2,\n",
    "    retain_train_records,\n",
    "    forget_val_2_records,\n",
    "    retain_val_records,\n",
    "    4,\n",
    "    forget_alpha=1,\n",
    "    eval_at_start=False,\n",
    "    log_steps=50,\n",
    "    lr=1e-5,\n",
    "    grad_accum_steps=8,\n",
    "    use_log_1_minus_p=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 314/314 [00:20<00:00, 15.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val 1 Accuracy: 0.23089171974522293\n",
      "Val 2 Accuracy: 0.19745222929936307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_1_acc = evaluate(model, forget_val_1_records, batch_size=8, normalize_loss=False)\n",
    "val_2_acc = evaluate(model, forget_val_2_records, batch_size=8, normalize_loss=False)\n",
    "print(f\"Val 1 Accuracy: {val_1_acc}\")\n",
    "print(f\"Val 2 Accuracy: {val_2_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from unlearn_order.utils import log_1_minus_p_loss, my_loss\n",
    "\n",
    "\n",
    "def train_step_ft(\n",
    "    model: AutoModelForCausalLM,\n",
    "    batch: Dict,\n",
    "):\n",
    "    batch = fix_seq_len(\n",
    "        batch, [\"input_ids\", \"attention_mask\", \"labels\", \"completion_mask\"]\n",
    "    )\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    completion_mask = batch[\"completion_mask\"].to(device)\n",
    "\n",
    "    # only train on completions for multiple choice\n",
    "    labels[~completion_mask.bool()] = -100\n",
    "\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = output.loss\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    loss = loss.detach().item()\n",
    "\n",
    "    loss_dict = {\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ft(\n",
    "    model: AutoModelForCausalLM,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    mcq_records: List[Dict],\n",
    "    batch_size: int = 4,\n",
    "    lr: float = 3e-5,\n",
    "    log_steps: int = 50,\n",
    "    grad_accum_steps: int = 1,\n",
    "):\n",
    "    model.train()\n",
    "    dataloader = DataLoader(mcq_records, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    loss_traj = []\n",
    "    for step, batch in tqdm(enumerate(dataloader)):\n",
    "        loss_dict = train_step_ft(model, batch)\n",
    "\n",
    "        if (step + 1) % grad_accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_traj.append(loss_dict)\n",
    "        if (step + 1) % log_steps == 0:\n",
    "            print(f\"Epoch {epoch}, Step {step}, Loss {loss_dict['loss']}\")\n",
    "\n",
    "    return loss_traj\n",
    "\n",
    "\n",
    "def train_ft(\n",
    "    model: AutoModelForCausalLM,\n",
    "    n_epochs: int,\n",
    "    mcq_records: List[Dict],\n",
    "    forget_val_1_records: List[Dict],\n",
    "    forget_val_2_records: List[Dict],\n",
    "    batch_size: int = 4,\n",
    "    lr: float = 3e-5,\n",
    "    log_steps: int = 50,\n",
    "    eval_at_start: bool = True,\n",
    "    grad_accum_steps: int = 1,\n",
    "):\n",
    "    if eval_at_start:\n",
    "        forget_acc_1 = evaluate(\n",
    "            model, forget_val_1_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "        forget_acc_2 = evaluate(\n",
    "            model, forget_val_2_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "\n",
    "        print(f\"Initial Forget accuracy 1: {forget_acc_1}\")\n",
    "        print(f\"Initial Forget accuracy 2: {forget_acc_2}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_epoch_ft(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            mcq_records,\n",
    "            batch_size,\n",
    "            lr=lr,\n",
    "            log_steps=log_steps,\n",
    "            grad_accum_steps=grad_accum_steps,\n",
    "        )\n",
    "        forget_acc_1 = evaluate(\n",
    "            model, forget_val_1_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "        forget_acc_2 = evaluate(\n",
    "            model, forget_val_2_records, batch_size=8, normalize_loss=False\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch}, Forget accuracy 1: {forget_acc_1}\")\n",
    "        print(f\"Epoch {epoch}, Forget accuracy 2: {forget_acc_2}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/314 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 314/314 [00:30<00:00, 10.39it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Forget accuracy 1: 0.5589171974522293\n",
      "Initial Forget accuracy 2: 0.4968152866242038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 49, Loss 0.051658716052770615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:36,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 99, Loss 0.0819343850016594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:54,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 149, Loss 0.05545036122202873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.74it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Forget accuracy 1: 0.6576433121019108\n",
      "Epoch 0, Forget accuracy 2: 0.43312101910828027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 49, Loss 0.027533534914255142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:36,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 99, Loss 0.06140691414475441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:55,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 149, Loss 0.11314509063959122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.74it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.47it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Forget accuracy 1: 0.7627388535031847\n",
      "Epoch 1, Forget accuracy 2: 0.4840764331210191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 49, Loss 0.04906626045703888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:37,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 99, Loss 0.028985515236854553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:55,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 149, Loss 0.01855723187327385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:58,  2.70it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.55it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Forget accuracy 1: 0.8949044585987261\n",
      "Epoch 2, Forget accuracy 2: 0.5159235668789809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 49, Loss 0.0007739756256341934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:36,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 99, Loss 0.0030363360419869423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:54,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 149, Loss 0.09721679985523224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.75it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Forget accuracy 1: 0.9713375796178344\n",
      "Epoch 3, Forget accuracy 2: 0.5477707006369427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:17,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 49, Loss 0.00062516366597265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:36,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 99, Loss 0.004087820183485746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:55,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 149, Loss 0.0011182192247360945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.73it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.57it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Forget accuracy 1: 0.9904458598726115\n",
      "Epoch 4, Forget accuracy 2: 0.5605095541401274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Step 49, Loss 0.0017534361686557531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:36,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Step 99, Loss 0.0005341760697774589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:55,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Step 149, Loss 0.0002668515662662685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.73it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.52it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Forget accuracy 1: 0.9888535031847133\n",
      "Epoch 5, Forget accuracy 2: 0.5987261146496815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Step 49, Loss 0.0005647400394082069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:36,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Step 99, Loss 0.0001643615833017975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:54,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Step 149, Loss 0.001968383090570569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.75it/s]\n",
      "100%|██████████| 314/314 [00:30<00:00, 10.26it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Forget accuracy 1: 1.0\n",
      "Epoch 6, Forget accuracy 2: 0.554140127388535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Step 49, Loss 7.853400165913627e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:36,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Step 99, Loss 0.0006252414896152914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:54,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Step 149, Loss 0.0003054819244425744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.74it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.57it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Forget accuracy 1: 1.0\n",
      "Epoch 7, Forget accuracy 2: 0.5477707006369427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:18,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Step 49, Loss 0.0005566880572587252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:37,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Step 99, Loss 0.0002648437221068889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:54,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Step 149, Loss 0.0005000761593692005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.74it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.60it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Forget accuracy 1: 1.0\n",
      "Epoch 8, Forget accuracy 2: 0.5477707006369427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:17,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Step 49, Loss 0.0003226958797313273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:35,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Step 99, Loss 0.00015773788618389517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:54,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Step 149, Loss 7.390901009785011e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:57,  2.75it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.59it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Forget accuracy 1: 1.0\n",
      "Epoch 9, Forget accuracy 2: 0.5477707006369427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft(\n",
    "    model,\n",
    "    10,\n",
    "    forget_val_1_train_records,\n",
    "    forget_val_1_records,\n",
    "    forget_val_2_records,\n",
    "    batch_size=4,\n",
    "    lr=1e-6,\n",
    "    log_steps=50,\n",
    "    eval_at_start=True,\n",
    "    grad_accum_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Forget accuracy 1: 1.0\n",
      "Initial Forget accuracy 2: 0.5477707006369427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:15,  2.63it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Forget accuracy 1: 0.9952229299363057\n",
      "Epoch 0, Forget accuracy 2: 0.732484076433121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.71it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.53it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Forget accuracy 1: 0.9984076433121019\n",
      "Epoch 1, Forget accuracy 2: 0.7961783439490446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.70it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.59it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Forget accuracy 1: 0.9968152866242038\n",
      "Epoch 2, Forget accuracy 2: 0.8853503184713376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.73it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Forget accuracy 1: 0.9920382165605095\n",
      "Epoch 3, Forget accuracy 2: 0.9363057324840764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.78it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Forget accuracy 1: 0.9840764331210191\n",
      "Epoch 4, Forget accuracy 2: 0.9617834394904459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.69it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Forget accuracy 1: 0.9888535031847133\n",
      "Epoch 5, Forget accuracy 2: 0.9808917197452229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.74it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Forget accuracy 1: 0.9761146496815286\n",
      "Epoch 6, Forget accuracy 2: 0.9936305732484076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.72it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Forget accuracy 1: 0.9777070063694268\n",
      "Epoch 7, Forget accuracy 2: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.76it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.58it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Forget accuracy 1: 0.9792993630573248\n",
      "Epoch 8, Forget accuracy 2: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.77it/s]\n",
      "100%|██████████| 314/314 [00:29<00:00, 10.59it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Forget accuracy 1: 0.9792993630573248\n",
      "Epoch 9, Forget accuracy 2: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft(\n",
    "    model,\n",
    "    10,\n",
    "    forget_val_2_train_records,\n",
    "    forget_val_1_records,\n",
    "    forget_val_2_records,\n",
    "    batch_size=4,\n",
    "    lr=1e-6,\n",
    "    log_steps=50,\n",
    "    eval_at_start=True,\n",
    "    grad_accum_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
